{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbcc9065-9fa6-42e5-ac6b-b6e2dd02ab1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import requests\n",
    "import re\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import time\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from rapidfuzz import process, fuzz\n",
    "from joblib import Parallel, delayed\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8183a3f-5552-48e5-b73f-7f67c23fdf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only needs to be run once to init async use\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "924ed9d4-c560-4344-b445-a1fabbc325b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load in csv of drugnames to normalize \n",
    "# drugname csv pipeline in drugname_load_in.ipynb\n",
    "drug_df = pd.read_csv(\"all_drugnames.csv\")\n",
    "drug_df = drug_df.drop_duplicates()\n",
    "drug_df['drugname'] = drug_df['drugname'].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0391f29-0bb6-41a6-815f-6927a79fe746",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# preprocesses drug names\n",
    "def strip_dose_form(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # Lowercase and remove content in parentheses\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\([^)]*\\)\", \"\", text)\n",
    "\n",
    "    # Remove dosage + form terms\n",
    "    text = re.sub(r\"\\b\\d+(\\.\\d+)?\\s?(mg|mcg|g|ml|iu|units?)\\b\", \"\", text)\n",
    "    text = re.sub(r\"\\b(tablet|tab|capsule|cap|injection|inj|oral|solution|suspension|spray|patch|cream|ointment|drop|dose|film)\\b\", \"\", text)\n",
    "\n",
    "    # Normalize whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    # Remove leading/trailing non-alphanumeric (keep slashes & dashes inside)\n",
    "    text = re.sub(r\"^[^\\w]+|[^\\w]+$\", \"\", text)\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "drug_df['rxnorm_input'] = drug_df['drugname'].apply(strip_dose_form)\n",
    "unique_inputs = sorted(drug_df['rxnorm_input'].dropna().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "653b1c76-742e-4d2d-8762-36ea35be2597",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 602917 unique individual drug parts to normalize.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Found {len(unique_inputs)} unique individual drug parts to normalize.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea2d7625-498b-4667-a487-eaae979c06b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_score(candidate):\n",
    "    return float(candidate.get(\"score\", 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c19ad92b-7bf9-43a1-9975-b58a4cb34a70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rxnorm querying function\n",
    "# single function call -> single drug query\n",
    "async def get_rxnorm_best_matches(session, name, attempt=1):\n",
    "    url = \"https://rxnav.nlm.nih.gov/REST/approximateTerm.json\"\n",
    "    params = {\"term\": name, \"maxEntries\": 15}\n",
    "    # sleep to delay api calls\n",
    "    await asyncio.sleep(0.2)\n",
    "\n",
    "    try:\n",
    "        async with session.get(url, params=params, timeout=5) as r:\n",
    "            # time-out api error\n",
    "            if r.status == 429:\n",
    "                # exponential delay for each repeat attempt\n",
    "                wait = 2 ** attempt\n",
    "                await asyncio.sleep(wait)\n",
    "                if attempt < 4:\n",
    "                    return await get_rxnorm_best_matches(session, name, attempt + 1)\n",
    "                else:\n",
    "                    # populate list to possibly retry later if needed\n",
    "                    failed_429_inputs.add(name)\n",
    "                    return name, None, None, None, None\n",
    "\n",
    "            elif r.status == 200:\n",
    "                data = await r.json()\n",
    "                candidates = data.get(\"approximateGroup\", {}).get(\"candidate\", [])\n",
    "                # if the rxnorm info returns no known synonyms return tuple of Nones\n",
    "                if not candidates:\n",
    "                    return name, None, None, None, None\n",
    "\n",
    "                # Sort candidates by score\n",
    "                candidates = sorted(candidates, key=get_score, reverse=True)\n",
    "                best = candidates[0]\n",
    "                \n",
    "                # highest score drug name (regardless of drug database source\n",
    "                best_name = best.get(\"name\", name)\n",
    "                best_rxcui = best.get(\"rxcui\")\n",
    "                \n",
    "                # get the best rxnorm source specific name if it exists\n",
    "                for c in candidates:\n",
    "                    rxcui = c.get(\"rxcui\")\n",
    "                    if not rxcui:\n",
    "                        continue\n",
    "                    props_url = f\"https://rxnav.nlm.nih.gov/REST/rxcui/{rxcui}/properties.json\"\n",
    "                    try:\n",
    "                        async with session.get(props_url, timeout=5) as pr:\n",
    "                            if pr.status == 200:\n",
    "                                props = await pr.json()\n",
    "                                meta = props.get(\"properties\", {})\n",
    "                                if meta.get(\"suppress\") != \"Y\" and meta.get(\"name\"):\n",
    "                                    if c.get(\"source\") == \"RXNORM\":\n",
    "                                        return name, best_name, best_rxcui, meta[\"name\"], rxcui\n",
    "                    except:\n",
    "                        continue\n",
    "                # if no rxnorm sourced names exist only populate with the highest scored drug name\n",
    "                return name, best_name, best_rxcui, None, None\n",
    "\n",
    "    except:\n",
    "        return name, None, None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a64c7a0-0d34-4863-be96-131f58df3974",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# batch function\n",
    "# runs query function on entire inputs list using async to not time-out api\n",
    "async def run_rxnorm_best_matches(inputs):\n",
    "    results = []\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [get_rxnorm_best_matches(session, name) for name in inputs]\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "        results.extend(responses)\n",
    "    # populated results tuple list for single batch\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc1d7dcf-01ba-4d05-a50d-e00de77d4169",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 took 1.72 seconds.\n",
      "Batch 2 took 1.67 seconds.\n",
      "Batch 3 took 1.68 seconds.\n",
      "Batch 4 took 2.16 seconds.\n",
      "Batch 5 took 1.73 seconds.\n",
      "Batch 6 took 1.74 seconds.\n",
      "Batch 7 took 1.71 seconds.\n",
      "Batch 8 took 1.80 seconds.\n",
      "Batch 9 took 1.71 seconds.\n",
      "Batch 10 took 3.93 seconds.\n",
      "Processed batch 50 of 10049\n",
      "Processed batch 100 of 10049\n",
      "Processed batch 150 of 10049\n",
      "Processed batch 200 of 10049\n",
      "Processed batch 250 of 10049\n",
      "Processed batch 300 of 10049\n",
      "Processed batch 350 of 10049\n",
      "Processed batch 400 of 10049\n",
      "Processed batch 450 of 10049\n",
      "Processed batch 500 of 10049\n",
      "Processed batch 550 of 10049\n",
      "Processed batch 600 of 10049\n",
      "Processed batch 650 of 10049\n",
      "Processed batch 700 of 10049\n",
      "Processed batch 750 of 10049\n",
      "Processed batch 800 of 10049\n",
      "Processed batch 850 of 10049\n",
      "Processed batch 900 of 10049\n",
      "Processed batch 950 of 10049\n",
      "Processed batch 1000 of 10049\n",
      "Processed batch 1050 of 10049\n",
      "Processed batch 1100 of 10049\n",
      "Processed batch 1150 of 10049\n",
      "Processed batch 1200 of 10049\n",
      "Processed batch 1250 of 10049\n",
      "Processed batch 1300 of 10049\n",
      "Processed batch 1350 of 10049\n",
      "Processed batch 1400 of 10049\n",
      "Processed batch 1450 of 10049\n",
      "Processed batch 1500 of 10049\n",
      "Processed batch 1550 of 10049\n",
      "Processed batch 1600 of 10049\n",
      "Processed batch 1650 of 10049\n",
      "Processed batch 1700 of 10049\n",
      "Processed batch 1750 of 10049\n",
      "Processed batch 1800 of 10049\n",
      "Processed batch 1850 of 10049\n",
      "Processed batch 1900 of 10049\n",
      "Processed batch 1950 of 10049\n",
      "Processed batch 2000 of 10049\n",
      "Processed batch 2050 of 10049\n",
      "Processed batch 2100 of 10049\n",
      "Processed batch 2150 of 10049\n",
      "Processed batch 2200 of 10049\n",
      "Processed batch 2250 of 10049\n",
      "Processed batch 2300 of 10049\n",
      "Processed batch 2350 of 10049\n",
      "Processed batch 2400 of 10049\n",
      "Processed batch 2450 of 10049\n",
      "Processed batch 2500 of 10049\n",
      "Processed batch 2550 of 10049\n",
      "Processed batch 2600 of 10049\n",
      "Processed batch 2650 of 10049\n",
      "Processed batch 2700 of 10049\n",
      "Processed batch 2750 of 10049\n",
      "Processed batch 2800 of 10049\n",
      "Processed batch 2850 of 10049\n",
      "Processed batch 2900 of 10049\n",
      "Processed batch 2950 of 10049\n",
      "Processed batch 3000 of 10049\n",
      "Processed batch 3050 of 10049\n",
      "Processed batch 3100 of 10049\n",
      "Processed batch 3150 of 10049\n",
      "Processed batch 3200 of 10049\n",
      "Processed batch 3250 of 10049\n",
      "Processed batch 3300 of 10049\n",
      "Processed batch 3350 of 10049\n",
      "Processed batch 3400 of 10049\n",
      "Processed batch 3450 of 10049\n",
      "Processed batch 3500 of 10049\n",
      "Processed batch 3550 of 10049\n",
      "Processed batch 3600 of 10049\n",
      "Processed batch 3650 of 10049\n",
      "Processed batch 3700 of 10049\n",
      "Processed batch 3750 of 10049\n",
      "Processed batch 3800 of 10049\n",
      "Processed batch 3850 of 10049\n",
      "Processed batch 3900 of 10049\n",
      "Processed batch 3950 of 10049\n",
      "Processed batch 4000 of 10049\n",
      "Processed batch 4050 of 10049\n",
      "Processed batch 4100 of 10049\n",
      "Processed batch 4150 of 10049\n",
      "Processed batch 4200 of 10049\n",
      "Processed batch 4250 of 10049\n",
      "Processed batch 4300 of 10049\n",
      "Processed batch 4350 of 10049\n",
      "Processed batch 4400 of 10049\n",
      "Processed batch 4450 of 10049\n",
      "Processed batch 4500 of 10049\n",
      "Processed batch 4550 of 10049\n",
      "Processed batch 4600 of 10049\n",
      "Processed batch 4650 of 10049\n",
      "Processed batch 4700 of 10049\n",
      "Processed batch 4750 of 10049\n",
      "Processed batch 4800 of 10049\n",
      "Processed batch 4850 of 10049\n",
      "Processed batch 4900 of 10049\n",
      "Processed batch 4950 of 10049\n",
      "Processed batch 5000 of 10049\n",
      "Processed batch 5050 of 10049\n",
      "Processed batch 5100 of 10049\n",
      "Processed batch 5150 of 10049\n",
      "Processed batch 5200 of 10049\n",
      "Processed batch 5250 of 10049\n",
      "Processed batch 5300 of 10049\n",
      "Processed batch 5350 of 10049\n",
      "Processed batch 5400 of 10049\n",
      "Processed batch 5450 of 10049\n",
      "Processed batch 5500 of 10049\n",
      "Processed batch 5550 of 10049\n",
      "Processed batch 5600 of 10049\n",
      "Processed batch 5650 of 10049\n",
      "Processed batch 5700 of 10049\n",
      "Processed batch 5750 of 10049\n",
      "Processed batch 5800 of 10049\n",
      "Processed batch 5850 of 10049\n",
      "Processed batch 5900 of 10049\n",
      "Processed batch 5950 of 10049\n",
      "Processed batch 6000 of 10049\n",
      "Processed batch 6050 of 10049\n",
      "Processed batch 6100 of 10049\n",
      "Processed batch 6150 of 10049\n",
      "Processed batch 6200 of 10049\n",
      "Processed batch 6250 of 10049\n",
      "Processed batch 6300 of 10049\n",
      "Processed batch 6350 of 10049\n",
      "Processed batch 6400 of 10049\n",
      "Processed batch 6450 of 10049\n",
      "Processed batch 6500 of 10049\n",
      "Processed batch 6550 of 10049\n",
      "Processed batch 6600 of 10049\n",
      "Processed batch 6650 of 10049\n",
      "Processed batch 6700 of 10049\n",
      "Processed batch 6750 of 10049\n",
      "Processed batch 6800 of 10049\n",
      "Processed batch 6850 of 10049\n",
      "Processed batch 6900 of 10049\n",
      "Processed batch 6950 of 10049\n",
      "Processed batch 7000 of 10049\n",
      "Processed batch 7050 of 10049\n",
      "Processed batch 7100 of 10049\n",
      "Processed batch 7150 of 10049\n",
      "Processed batch 7200 of 10049\n",
      "Processed batch 7250 of 10049\n",
      "Processed batch 7300 of 10049\n",
      "Processed batch 7350 of 10049\n",
      "Processed batch 7400 of 10049\n",
      "Processed batch 7450 of 10049\n",
      "Processed batch 7500 of 10049\n",
      "Processed batch 7550 of 10049\n",
      "Processed batch 7600 of 10049\n",
      "Processed batch 7650 of 10049\n",
      "Processed batch 7700 of 10049\n",
      "Processed batch 7750 of 10049\n",
      "Processed batch 7800 of 10049\n",
      "Processed batch 7850 of 10049\n",
      "Processed batch 7900 of 10049\n",
      "Processed batch 7950 of 10049\n",
      "Processed batch 8000 of 10049\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# use the batch query function to query on entire batch\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 15\u001b[0m     batch_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m run_rxnorm_best_matches(batch)\n\u001b[1;32m     16\u001b[0m     rxnorm_results\u001b[38;5;241m.\u001b[39mextend(batch_result)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m, in \u001b[0;36mrun_rxnorm_best_matches\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m aiohttp\u001b[38;5;241m.\u001b[39mClientSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m      6\u001b[0m     tasks \u001b[38;5;241m=\u001b[39m [get_rxnorm_best_matches(session, name) \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m inputs]\n\u001b[0;32m----> 7\u001b[0m     responses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mtasks)\n\u001b[1;32m      8\u001b[0m     results\u001b[38;5;241m.\u001b[39mextend(responses)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# populated results tuple list for single batch\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/asyncio/tasks.py:385\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 385\u001b[0m         future\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    387\u001b[0m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[1;32m    388\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step(exc)\n",
      "\u001b[0;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "failed_429_inputs = set()\n",
    "rxnorm_results = []\n",
    "\n",
    "for i in range(0, len(unique_inputs), batch_size):\n",
    "    batch_num = i // batch_size + 1\n",
    "    batch = unique_inputs[i:i + batch_size]\n",
    "\n",
    "    # uncomment if statement below to gauge time per batch\n",
    "    if batch_num <= 10:\n",
    "        start = time.time()\n",
    "    \n",
    "    # use the batch query function to query on entire batch\n",
    "    try:\n",
    "        batch_result = await run_rxnorm_best_matches(batch)\n",
    "        rxnorm_results.extend(batch_result)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in batch {batch_num}: {e}\")\n",
    "\n",
    "    # uncomment if statement below to gauge time per batch\n",
    "    if batch_num <= 10:\n",
    "        end = time.time()\n",
    "    \n",
    "    # uncomment if statement below to gauge time per batch\n",
    "    # Print timing for batches 1–10\n",
    "    if batch_num <= 10:\n",
    "        print(f\"Batch {batch_num} took {end - start:.2f} seconds.\")\n",
    "\n",
    "    # save checkpoint every 10 batches to prevent lost progress if error ocurrs\n",
    "    if batch_num % 10 == 0:\n",
    "        with open(\"rxnorm_results_checkpoint.json\", \"w\") as f:\n",
    "            json.dump(rxnorm_results, f)\n",
    "\n",
    "    # progress print every 50 batches\n",
    "    if batch_num % 50 == 0:\n",
    "        print(f\"Processed batch {batch_num} of {len(unique_inputs) // batch_size + 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f876d0-69d7-472b-8015-d5c4716b33ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(failed_429_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a36fde0e-5365-4f03-af5d-0e530d9a24b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# UNCOMMENT BELOW\n",
    "\n",
    "# below code retries timed-out drug queries\n",
    "\n",
    "# retry_inputs = list(failed_429_inputs.copy())\n",
    "# # smaller batch size to attempt to populate failed queries\n",
    "# batch_size = 10\n",
    "# failed_429_inputs = set()\n",
    "# retry_results = []\n",
    "\n",
    "# for i in range(0, len(retry_inputs), batch_size):\n",
    "#     batch_num = i // batch_size + 1\n",
    "#     batch = retry_inputs[i:i + batch_size]\n",
    "\n",
    "#     # Start timing\n",
    "#     start = time.time()\n",
    "\n",
    "#     try:\n",
    "#         batch_result = await run_rxnorm_best_matches(batch)\n",
    "#         retry_results.extend(batch_result)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error in batch {batch_num}: {e}\")\n",
    "\n",
    "#     # End timing\n",
    "#     end = time.time()\n",
    "    \n",
    "#     # Print timing for batches 1–10\n",
    "#     if batch_num <= 10:\n",
    "#         print(f\"Batch {batch_num} took {end - start:.2f} seconds.\")\n",
    "\n",
    "#     # Save checkpoint every 10 batches\n",
    "#     if batch_num % 10 == 0:\n",
    "#         with open(\"retry_results_checkpoint.json\", \"w\") as f:\n",
    "#             json.dump(rxnorm_results, f)\n",
    "\n",
    "#     # Progress print every 50 batches\n",
    "#     if batch_num % 50 == 0:\n",
    "#         print(f\"Processed batch {batch_num} of {len(retry_inputs) // batch_size + 1}\")\n",
    "\n",
    "# rxnorm_results.extend(retry_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e341148-cf1a-4153-b02e-3d63344f3a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weird single None value at start of rxnorm_results\n",
    "rxnorm_results = rxnorm_results[1:]\n",
    "\n",
    "rxnorm_df = pd.DataFrame(\n",
    "    rxnorm_results,\n",
    "    columns=[\"drugname\", \"best_match_name\", \"best_match_rxcui\", \"rxnorm_name\", \"rxnorm_rxcui\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8636259-538c-4da6-8ccf-b477fb5be3a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# UNCOMMENT BELOW if you used the failed inputs retry query code\n",
    "\n",
    "# score_cols = [\"best_match_name\", \"best_match_rxcui\", \"rxnorm_name\", \"rxnorm_rxcui\"]\n",
    "# rxnorm_df[\"non_null_score\"] = rxnorm_df[score_cols].notna().sum(axis=1)\n",
    "# rxnorm_df = rxnorm_df.sort_values(\"non_null_score\", ascending=False)\n",
    "# rxnorm_df = rxnorm_df.drop_duplicates(subset=\"input_name\", keep=\"first\")\n",
    "# rxnorm_df = rxnorm_df.sort_values(\"non_null_score\", ascending=False)\n",
    "# rxnorm_df = rxnorm_df.drop_duplicates(subset=\"input_name\", keep=\"first\")\n",
    "# rxnorm_df = rxnorm_df.drop(columns=[\"non_null_score\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936862c1-df94-4863-a062-fb697262fb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save query output to be safe\n",
    "rxnorm_df.to_csv('data_files/rxnorm_output_df.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3aa5ea40-abee-4ee4-90af-863984cf9fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge new query-result columns into original drug_df\n",
    "drug_df = drug_df.merge(rxnorm_df, on=\"rxnorm_input\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb2527f0-c8dc-4762-92d7-fc68154bda94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drugname</th>\n",
       "      <th>drugname_clean</th>\n",
       "      <th>rxnorm_input</th>\n",
       "      <th>rxnorm_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LETROZOLE</td>\n",
       "      <td>letrozole</td>\n",
       "      <td>letrozole</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LAPATINIB</td>\n",
       "      <td>lapatinib</td>\n",
       "      <td>lapatinib</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FULVESTRANT</td>\n",
       "      <td>fulvestrant</td>\n",
       "      <td>fulvestrant</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAPECITABINE</td>\n",
       "      <td>capecitabine</td>\n",
       "      <td>capecitabine</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRASTUZUMAB</td>\n",
       "      <td>trastuzumab</td>\n",
       "      <td>trastuzumab</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75471440</th>\n",
       "      <td>VANCOMYCIN</td>\n",
       "      <td>vancomycin</td>\n",
       "      <td>vancomycin</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75471441</th>\n",
       "      <td>DIOVAN</td>\n",
       "      <td>diovan</td>\n",
       "      <td>diovan</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75471442</th>\n",
       "      <td>DIOVAN</td>\n",
       "      <td>diovan</td>\n",
       "      <td>diovan</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75471443</th>\n",
       "      <td>ANTIDIABETICS</td>\n",
       "      <td>antidiabetics</td>\n",
       "      <td>antidiabetics</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75471444</th>\n",
       "      <td>INSULIN</td>\n",
       "      <td>insulin</td>\n",
       "      <td>insulin</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75471445 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               drugname drugname_clean   rxnorm_input rxnorm_name\n",
       "0             LETROZOLE      letrozole      letrozole        None\n",
       "1             LAPATINIB      lapatinib      lapatinib        None\n",
       "2           FULVESTRANT    fulvestrant    fulvestrant        None\n",
       "3          CAPECITABINE   capecitabine   capecitabine        None\n",
       "4           TRASTUZUMAB    trastuzumab    trastuzumab        None\n",
       "...                 ...            ...            ...         ...\n",
       "75471440     VANCOMYCIN     vancomycin     vancomycin        None\n",
       "75471441         DIOVAN         diovan         diovan        None\n",
       "75471442         DIOVAN         diovan         diovan        None\n",
       "75471443  ANTIDIABETICS  antidiabetics  antidiabetics        None\n",
       "75471444        INSULIN        insulin        insulin        None\n",
       "\n",
       "[75471445 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_df.to_csv('data_files/full_final_mapping.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6a514237-e8ac-407f-875c-6e6989af3c6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing normalized names: 725403\n"
     ]
    }
   ],
   "source": [
    "num_none = drug_df['rxnorm_name'].isna().sum()\n",
    "print(f\"Number of missing normalized names: {num_none}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae38e065-e8e1-4ce0-94bf-ce5e34b72cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_none = rxnorm_df['best_match_name'].isna().sum()\n",
    "print(f\"Number of missing normalized names: {num_none}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e902c892-37d8-4309-b8a2-10bcc8bb1aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_none_rxnorm = rxnorm_df['rxnorm_name'].isna().sum()\n",
    "print(f\"Number of missing rxnorm normalized names: {num_none_rxnorm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7f594a-afb3-453e-a00c-f1faa58fe559",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Normalized {len(rxnorm_df_retry) - num_none}/{len(rxnorm_df_retry)} names.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e60d0b2-7ac9-4be7-9765-dfc21cdca343",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Rxnorm normalized {len(rxnorm_df_retry) - num_none_rxnorm}/{len(rxnorm_df_retry)} names.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345b00d6-b8c3-464d-92a2-f22627ad4141",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_num_none = drug_df['best_match_name'].isna().sum()\n",
    "print(f\"Number of missing normalized names from drug_df: {drug_num_none}\")\n",
    "print(f\"Normalized {len(drug_df) - drug_num_none}/{len(drug_df)} drugs.\")\n",
    "drug_num_none_rxnorm = drug_df['rxnorm_name'].isna().sum()\n",
    "print(f\"Number of missing rxnorm normalized names from drug_df: {drug_num_none_rxnorm}\")\n",
    "print(f\"Rxnorm normalized {len(drug_df) - drug_num_none_rxnorm}/{len(drug_df)} drugs.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
